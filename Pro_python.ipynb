{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.graph_objects as go\nfrom ipywidgets import widgets\nimport seaborn as sns\nimport folium\nfrom folium.plugins import TimestampedGeoJson\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_2016=pd.read_csv(\"/kaggle/input/air-pollution-dataset-india20162018/2016_india.csv\")\ndf_2017=pd.read_csv(\"/kaggle/input/air-pollution-dataset-india20162018/2017_india.csv\")\ndf_2018=pd.read_csv(\"/kaggle/input/air-pollution-dataset-india20162018/2018_india.csv\")\ndf_temp=df_2016.append(df_2017,ignore_index=True)\ndf=df_temp.append(df_2018,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking lat,long for each city and putting in dict().\ndict_lat={}\ndict_long={}\ndf_clean=df.groupby(df['city']).mean()\nfor i in df_clean.index:\n    dict_lat[i]=df_clean.latitude[i]\n    dict_long[i]=df_clean.longitude[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Iterate through everything and replace each row. Not efficient but works.We need to replace in same dataframe \n#to keep the time series so that we can plot\n\n#-------------!!!!!!!!!!!!!!TAKES AROUND 40 MINS!!!!!!!!!!!!!!!!!!!------------------\nfor i in df.index:\n    df.latitude[i]=dict_lat[df.city[i]]\n    df.longitude[i]=dict_long[df.city[i]]\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaning negative values\ndrop_l=df.index[df['value'] < 0].tolist()\ndf=df.drop(df.index[drop_l])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaning out of range values\n#so2\ndrop_l_so2=df.index[df['value'] > 300].tolist()\ndf=df.drop(df.index[drop_l_so2])\n#no2\ndrop_l_no2=df.index[df['value'] > 480].tolist()\ndf=df.drop(df.index[drop_l_no2])\n#co\ndrop_l_co=df.index[df['value'] > 20000].tolist()\ndf=df.drop(df.index[drop_l_co])\n#pm25\ndrop_l_pm25=df.index[df['value'] > 300].tolist()\ndf=df.drop(df.index[drop_l_pm25])\n#pm10\ndrop_l_pm10=df.index[df['value'] > 260].tolist()\ndf=df.drop(df.index[drop_l_pm10])\n#o3\ndrop_l_o3=df.index[df['value'] > 420].tolist()\ndf=df.drop(df.index[drop_l_o3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------Code for pushing the df into a csv file---------------","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking how many rows still have NA even after putting by city\nprint(df.latitude.isna().sum())\n#Dropping rest\ndf=df.dropna(axis=0)\ndf.latitude.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pie Chart for pollutant proportion\nvalues=[]\npar=df.parameter.value_counts()\nfor i in range(len(par)):\n    values.append(par[i])\nlabels=['no2','co','pm25','o3','so2','pm10']\ncolors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen','red','black']\nfig_pie = go.Figure(data=[go.Pie(labels=labels, \n                             values=values)])\nfig_pie.update_traces(hoverinfo='label+percent', textinfo='percent', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig_pie.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Right now dropping NA but once Bhavya fills it with the lat long it can be removed\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#---For MAP\n#Creating a new dataframe \ndata_monthly_dropdown=df\ndata_monthly_dropdown=data_monthly_dropdown.drop(['local','country','attribution','location','unit'],axis=1)\ndata_monthly_dropdown['utc'] = data_monthly_dropdown['utc'].map(lambda x: str(x)[:-17])\n#Converting to datetime\ndata_monthly_dropdown['utc']=pd.to_datetime(data_monthly_dropdown['utc'],format=\"%Y-%m\")\n\n#Creating an aggregated dataframe\nagg_monthly_dropdown=data_monthly_dropdown\n#Grouping by the 3 columns to get unique values\ngrouped_monthly_dropdown=agg_monthly_dropdown.groupby(['utc','city','parameter'])\n#Getting mean of each column\ngrouped_monthly_dropdown=grouped_monthly_dropdown.mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding new columns for ease of work\ngrouped_monthly_dropdown.insert(3,'date',pd.to_datetime('2016-01'))\ngrouped_monthly_dropdown.insert(4,'city',0)\ngrouped_monthly_dropdown.insert(5,'parameter',0)\n\nfor i in grouped_monthly_dropdown.index:\n    grouped_monthly_dropdown.date[i]=i[0]\n    grouped_monthly_dropdown.city[i]=i[1]\n    grouped_monthly_dropdown.parameter[i]=i[2]\n    #print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#---MAIN DROPDOWN\n#Creating a new dataframe where I have removed the time part of utc because we will be working with daily data and not fine grained to hourly\ndata_dropdown=df\ndata_dropdown=data_dropdown.drop(['local','country','attribution','location'],axis=1)\ndata_dropdown['utc'] = data_dropdown['utc'].map(lambda x: str(x)[:-14])\n#Converting to datetime\ndata_dropdown['utc']=pd.to_datetime(data_dropdown['utc'],format=\"%Y-%m-%d\")\n\n#Creating an aggregated dataframe\nagg_data_dropdown=data_dropdown\n#Grouping by the 3 columns to get unique values\ngrouped_dropdown=agg_data_dropdown.groupby(['utc','city','parameter'])\n#Getting mean of each column\ngrouped_dropdown=grouped_dropdown.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So basically now what we get is a heirarchically indexed dataframe, so the three columns together form the index and are no more\n#available as separate columns\ngrouped_dropdown","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inserting those columns from the index again so that we can make accessing easier\ngrouped_dropdown.insert(3,'date',pd.to_datetime('2016-01-03'))\ngrouped_dropdown.insert(4,'parameter',0)\ngrouped_dropdown.insert(5,'city',0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copying the values from index to the newly added row\nfor i in grouped_dropdown.index:\n    grouped_dropdown.date[i]=i[0]\n    grouped_dropdown.parameter[i]=i[2]\n    grouped_dropdown.city[i]=i[1]\n    #print(grouped_dropdown.date[i])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropdown without cleaning, there are negative values\n\nfilter_list = [i and j for i, j in\n        zip(grouped_dropdown['city'] == 'Delhi', grouped_dropdown['parameter'] == 'co')]\ntemp_df = grouped_dropdown[filter_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ncity = widgets.Dropdown(\n    description='City:   ',\n    value='Delhi',\n    options=grouped_dropdown['city'].unique().tolist()\n)\nparameter = widgets.Dropdown(\n    options=list(grouped_dropdown['parameter'].unique()),\n    value='co',\n    description='Parameter:   ',\n)\ntrace1 = go.Scatter(x=temp_df['date'], y=temp_df['value'], mode='markers')\n\ng = go.FigureWidget(data=[trace1],\n                    layout=go.Layout(\n                        title=dict(\n                            text='AQI for different cities'\n                        )\n                    ))\ndef response(change):\n        filter_list = [i and j for i, j in\n        zip(grouped_dropdown['city'] == city.value, grouped_dropdown['parameter'] == parameter.value)]\n        temp_df = grouped_dropdown[filter_list]\n        x1 = temp_df['date']\n        y1 = temp_df['value']\n        with g.batch_update():\n            g.data[0].x = x1\n            g.data[0].y = y1\n            g.layout.xaxis.title = 'Date'\n            g.layout.yaxis.title = 'Pollutant levels'\n\n\ncity.observe(response, names=\"value\")\nparameter.observe(response, names=\"value\")\ncontainer2 = widgets.HBox([city, parameter])\nwidgets.VBox([container2,g])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#------------------TRYING MAP-------------------\n#get max,min for each parameter. according to max,min set x steps. use that.\n#x=range(min,max,10)\npollutants = {\n    'so2': {\n        'notation' : 'SO2',\n        'name' :'Sulphur dioxide',\n        'bin_edges' : np.array([15,30,45,60,80,100,125,165,250])\n    },\n    'pm10': {\n        'notation' : 'PM10',\n        'name' :'Particulate matter < 10 Âµm',\n        'bin_edges' : np.array([10,20,30,40,50,70,100,150,200])\n    },\n    'o3': {'notation' : 'O3',\n        'name' :'Ozone',\n        'bin_edges' : np.array([30,50,70,90,110,145,180,240,360])\n    },\n    'no2': {'notation' : 'NO2',\n        'name' :'Nitrogen dioxide',\n        'bin_edges' : np.array([25,45,60,80,110,150,200,270,400])\n    },\n    'co': {'notation' : 'CO',\n        'name' :'Carbon monoxide',\n         'bin_edges' : np.array([1.4,2.1,2.8,3.6,4.5,5.2,6.6,8.4,13.7])\n    },\n    'pm25': {\n        'notation' : 'PM25',\n        'name' :'Particulate matter < 25 Âµm',\n        'bin_edges' : np.array([10,20,30,40,50,70,100,150,200])\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncolor_scale = np.array(['#10ff00','#99ff00','#ccff00','#ffff00','#ffee00','#FFCC00','#ff9900','#ff6600','#ff0000','#960018'])\nsns.palplot(sns.color_palette(color_scale))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(pollutant_ID):\n    print('> Loading data...')\n    agg_ts = grouped_monthly_dropdown[grouped_monthly_dropdown['parameter']==pollutant_ID]\n    return agg_ts\n\ndef color_coding(poll, bin_edges):    \n    idx = np.digitize(poll, bin_edges, right=True)\n    return color_scale[idx]\n\n\ndef prepare_data(df, pollutant_ID):\n    print('> Preparing data...')\n    #df = df.reset_index().merge(meta, how='inner', on='city').set_index('DatetimeBegin')\n    #df = df.loc[:, ['SamplingPoint','Latitude', 'Longitude', 'AirPollutionLevel']]\n    #df = df.groupby('SamplingPoint', group_keys=False).resample(rule='M').last().reset_index()\n    df['color'] = df.value.apply(color_coding, bin_edges=pollutants[pollutant_ID]['bin_edges'])\n    return df\n\ndef create_geojson_features(df):\n    print('> Creating GeoJSON features...')\n    features = []\n    for _, row in df.iterrows():\n        feature = {\n            'type': 'Feature',\n            'geometry': {\n                'type':'Point', \n                'coordinates':[row['longitude'],row['latitude']]\n            },\n            'properties': {\n                'time': row['date'].date().__str__(),\n                'style': {'color' : row['color']},\n                'icon': 'circle',\n                'iconstyle':{\n                    'fillColor': row['color'],\n                    'fillOpacity': 0.8,\n                    'stroke': 'true',\n                    'radius': 7\n                }\n            }\n        }\n        features.append(feature)\n    return features\n\ndef make_map(features):\n    print('> Making map...')\n    coords_belgium=[28.65381,77.22897]\n    pollution_map = folium.Map(location=coords_belgium, control_scale=True, zoom_start=8)\n\n    TimestampedGeoJson(\n        {'type': 'FeatureCollection',\n        'features': features}\n        , period='P1M'\n        , add_last_point=True\n        , auto_play=False\n        , loop=False\n        , max_speed=1\n        , loop_button=True\n        , date_options='YYYY/MM'\n        , time_slider_drag_update=True\n    ).add_to(pollution_map)\n    print('> Done.')\n    return pollution_map\n\ndef plot_pollutant(pollutant_ID):\n    print('Mapping {} pollution in Belgium in 2013-2015'.format(pollutants[pollutant_ID]['name']))\n    pollutant_map_df = load_data(pollutant_ID)\n    #df = clean_data(df)\n    pollutant_map_df = prepare_data(pollutant_map_df, pollutant_ID)\n    features = create_geojson_features(pollutant_map_df)\n    return make_map(features), pollutant_map_df\n\n#Change the name below to any polllutant you want i.e pollution_map, df = plot_pollutant('no2')\npollution_map, pollutant_map_df = plot_pollutant('pm25')\npollution_map.save('/kaggle/input/pollution_so2.html')\npollution_map\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}